{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [04/Apr/2025 08:41:10] \"GET /chat HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [04/Apr/2025 08:41:28] \"GET /chat HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN,Dense,TimeDistributed,LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd \n",
    "import os\n",
    "import nltk\n",
    "from threading import Thread\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/macbookpro2019/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Id</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Semarang, Jawa Tengah</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bekasi, Jawa Barat</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cirebon, Jawa Barat</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bekasi, Jawa Barat</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lampung, Sumatera Selatan</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>296</td>\n",
       "      <td>Lampung, Sumatera Selatan</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>297</td>\n",
       "      <td>Palembang, Sumatera Selatan</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>298</td>\n",
       "      <td>Bogor, Jawa Barat</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>Sragen, Jawa Tengah</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>300</td>\n",
       "      <td>Ponorogo, Jawa Timur</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User_Id                     Location  Age\n",
       "0          1        Semarang, Jawa Tengah   20\n",
       "1          2           Bekasi, Jawa Barat   21\n",
       "2          3          Cirebon, Jawa Barat   23\n",
       "3          4           Bekasi, Jawa Barat   21\n",
       "4          5    Lampung, Sumatera Selatan   20\n",
       "..       ...                          ...  ...\n",
       "295      296    Lampung, Sumatera Selatan   31\n",
       "296      297  Palembang, Sumatera Selatan   39\n",
       "297      298            Bogor, Jawa Barat   38\n",
       "298      299          Sragen, Jawa Tengah   27\n",
       "299      300         Ponorogo, Jawa Timur   26\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tourism_info = pd.read_csv(\"tourism_with_id.csv\")\n",
    "tourism_rating = pd.read_csv(\"tourism_rating.csv\")\n",
    "users = pd.read_csv(\"user.csv\")\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Dataset  Tourism and User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan dataset dengan kunci yang benar\n",
    "merged_data = tourism_info.merge(tourism_rating, on=\"Place_Id\", how=\"left\")  # Gunakan Place_Id\n",
    "merged_data = merged_data.merge(users, on=\"User_Id\", how=\"left\")  # Gunakan User_Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ambil hanya kolom yang relevan\n",
    "dataset = merged_data[['Place_Name', 'Description']].dropna().head(1000)\n",
    "dataset.rename(columns={'Place_Name': 'question', 'Description': 'answer'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisasi data\n",
    "questions = dataset[\"question\"].tolist()\n",
    "answers = dataset[\"answer\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Inisialisasi tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi tokenizer\n",
    "vocab_size = 2000  # Pastikan vocab_size cukup besar\n",
    "tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(questions + answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konversi teks ke urutan token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi teks ke urutan token\n",
    "X = tokenizer.texts_to_sequences(questions)\n",
    "y = tokenizer.texts_to_sequences(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil panjang sequence maksimal dari X\n",
    "max_sequence_length = max(len(seq) for seq in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terapkan padding ke semua sequence agar memiliki panjang yang sama\n",
    "X = pad_sequences(X, maxlen=max_sequence_length, padding='post')\n",
    "y = pad_sequences(y, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konversi output menjadi one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi y ke one-hot encoding dengan ukuran vocab yang benar\n",
    "y = np.array([np.eye(vocab_size)[seq] for seq in y])  # One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "embedding_dim = 64\n",
    "lstm_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(vocab_size, embedding_dim, lstm_units, max_sequence_length):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, input_length=max_sequence_length),\n",
    "        LSTM(lstm_units, return_sequences=True),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax'))  # Output sesuai vocab_size\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model():\n",
    "    model = build_model(vocab_size, embedding_dim, lstm_units, max_sequence_length)\n",
    "    print(\"Starting model training...\")\n",
    "    model.fit(X, y, epochs=20, batch_size=4, verbose=1)\n",
    "    print(\"Model training completed.\")\n",
    "    model.save('chatbot_lstm.h5')\n",
    "    print(\"Model saved as chatbot_lstm.h5.\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek apakah model sudah ada, jika tidak maka latih model\n",
    "if not os.path.exists('chatbot_lstm.h5'):\n",
    "    train_and_save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load model yang telah disimpan\n",
    "model = load_model('chatbot_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.view_functions.pop('predict', None)  # Hapus jika sudah ada\n",
    "app.view_functions.pop('chat', None)     # Hapus jika sudah ada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/chat', methods=['GET', 'POST'])\n",
    "def chat():\n",
    "    if request.method == 'GET':\n",
    "        return jsonify({'response': 'Selamat datang'})\n",
    "\n",
    "    elif request.method == 'POST':\n",
    "        user_input = request.json.get('text', '')\n",
    "        seq = tokenizer.texts_to_sequences([user_input])\n",
    "        seq = pad_sequences(seq, maxlen=X.shape[1], padding='post')\n",
    "\n",
    "        prediction = model.predict(seq)\n",
    "        response_idx = np.argmax(prediction, axis=-1)[0]\n",
    "        response = tokenizer.index_word.get(response_idx, \"Maaf, saya tidak mengerti.\")\n",
    "\n",
    "        return jsonify({'response': response})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:12000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [04/Apr/2025 08:38:13] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [04/Apr/2025 08:38:14] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [04/Apr/2025 08:38:16] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [04/Apr/2025 08:38:20] \"GET /chat HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    Thread(target=lambda: app.run(debug=True, port=12000,use_reloader=False)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
